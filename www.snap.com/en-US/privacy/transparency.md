Transparency Report
July 1, 2022 – December 31, 2022
Released:
June 20, 2023
Updated:
June 20, 2023
To provide insight into Snap’s safety efforts and the nature and volume of content reported on our platform, we publish transparency reports twice a year. We are committed to continuing to make these reports more comprehensive and informative to the many stakeholders who care deeply about our content moderation and law enforcement practices, as well as the  well-being of our community. 
This report covers the second half of 2022 (July 1 - December 31). As with our previous reports, we share data about the global number of in-app content and account-level reports we received and enforced against across specific categories of policy violations; how we responded to requests from law enforcement and governments; and our enforcement actions broken down by country. It also captures recent additions to this report, including the Violative View Rate of Snapchat content, potential trademark violations, and incidences of false information on the platform.

As part of our ongoing commitment to continually improve our transparency reports, we are introducing a few new elements with this release. We have added a section labeled “Analysis of Content and Account Violations” wherein we assess major data changes relative to our previous reporting period. 
In addition, we have updated how we present data in our content and account violations tables, both on the landing page and our country sub-pages. Previously, we ordered violations from most to least content enforcements. To improve consistency, our ordering now mirrors our Community Guidelines. This came at the suggestion of Snap’s Safety Advisory Board, which independently educates, challenges, raises issues to, and advises Snap on how to help keep the Snapchat community safe.
Finally, we have updated our Glossary with links to our Community Guidelines Explainers, which provide additional context around our platform policy and operational efforts. 
For more information about our policies for combating online harms, and plans to continue evolving our reporting practices, please read our recent Safety & Impact blog about this transparency report. 
To find additional resources for safety and privacy on Snapchat, see our About Transparency Reporting tab at the bottom of the page.
Overview of Content and Account Violations
From July 1 - December, 2022, Snap enforced against 6,360,594 pieces of content globally that violated our policies. 
During the reporting period, we saw a Violative View Rate (VVR) of 0.03 percent, which means that out of every 10,000 Snap and Story views on Snapchat, 3 contained content that violated our policies.
Total Content & Account Reports	Total Content Enforced	Total Unique Accounts Enforced
17,821,535	6,360,594	3,629,674
Reason	Content & Account Reports	Content Enforced	% of Total Content Enforced	Unique Accounts Enforced	Turnaround Time (in median minutes)
Sexual Content	7,537,979	4,328,702	67.9%	2,377,013	6
Harassment and Bullying	4,246,917	660,317	10.4%	571,126	6
Threats & Violence	753,467	167,811	2.6%	132,915	24
Self-Harm & Suicide	129,785	20,054	0.3%	18,311	24
False Information*	341,186	1,065	0.1%	812	18
Impersonation	2,523,292	14,431	0.2%	13,927	4
Spam	1,163,383	657,077	10.3%	523,730	4
Drugs	654,715	293,018	4.6%	202,098	25
Weapons	93,738	33,935	0.5%	26,347	20
Other Regulated Goods	164,527	133,177	2.1%	97,621	26
Hate Speech	212,546	51,007	0.8%	43,496	30
*Correctly and consistently enforcing against false information is a dynamic process that requires up-to-date context and diligence.  As we strive to continually improve the precision of our agents’ enforcement in this category, we have chosen, since H1 2022, to report figures in the "Content Enforced" and "Unique Accounts Enforced" categories that are estimated based on a rigorous quality-assurance review of a statistically significant portion of false information enforcements.  Specifically, we sample a statistically significant portion of false information enforcements across each country and quality-check the enforcement decisions.  We then use those quality-checked enforcements to derive enforcement rates with a 95% confidence interval (+/- 5% margin of error), which we use to calculate the false information enforcements reported in the Transparency Report.  
Analysis of Content and Account Violations
We saw a 38% increase in total content and account reports this cycle, which can be attributed to an update in our in-app reporting menu for accounts, which, in turn, provided Snapchatters with more options for reporting. Consequently, we saw a 12% increase in total content enforced, and a 40% increase in total unique accounts enforced. In particular, Snapchatters reported more content and accounts in the Harassment & Bullying and Other Regulated Goods categories, which saw ~300% and ~100% increases in reports, respectively, and ~83% and ~86% increases in content enforcements, respectively. We also recognized ~68% increase reports and ~88% increase in content enforcements for Spam. 
Additionally, the greater number of content and account reports resulted in increases in turnaround times for enforcing on content and accounts. The median turnaround time for all content and accounts still remains under 1 hour for all categories.    
Overall, while we saw general increases across the board, we believe it is important to continue to improve the tools our community use to actively and accurately report violations as they appear on the platform
Combating Child Sexual Exploitation & Abuse
The sexual exploitation of any member of our community, especially minors, is illegal, abhorrent, and prohibited by our Community Guidelines. Preventing, detecting, and eradicating Child Sexual Exploitation and Abuse Imagery (CSEAI) on our platform is a top priority for Snap, and we continually evolve our capabilities to combat these and other crimes.
Our Trust & Safety team uses active technology detection tools, such as PhotoDNA robust hash-matching and Google’s Child Sexual Abuse Imagery (CSAI) Match to identify known illegal images and videos of child sexual abuse, respectively, and report them to the U.S. National Center for Missing and Exploited Children (NCMEC), as required by law. NCMEC then, in turn, coordinates with domestic or international law enforcement, as required.
In the second half of 2022, we proactively detected and actioned 94 percent of the total child sexual exploitation and abuse violations reported here.
	Total Content Enforced	Total Account Deletions	Total Submissions to NCMEC*
CSEAI	527,787	204,490	265,285
**Note that each submission to NCMEC can contain multiple pieces of content. The total individual pieces of media submitted to NCMEC is equal to our total content enforced.
Terrorist and Violent Extremist Content
During the reporting period, we removed 132 accounts for violations of our policy prohibiting terrorist and violent extremist content.
At Snap, we remove terrorist and violent extremism content reported through multiple channels. These include encouraging users to report terrorist and violent extremist content through our in-app reporting menu, and we work closely with law enforcement to address terrorist and violent extremist content that may appear on Snap.
Total Account Deletions
132
Self-harm and Suicide Content
We care deeply about the mental health and well-being of Snapchatters, which has informed – and continues to inform – our decisions to build Snapchat differently. As a platform designed for communications between real friends, we believe Snapchat can play a unique role in empowering friends to help each other through difficult times.
When our Trust & Safety team recognizes a Snapchatter in distress, they can forward self-harm prevention and support resources, and notify emergency response personnel when appropriate. The resources that we share are available on our global list of safety resources, and these are publicly available to all Snapchatters.
Total Times Suicide Resources Shared
22,474
Country Overview
This section provides an overview of the enforcement of our Community Guidelines in a sampling of geographic regions. Our Guidelines apply to all content on Snapchat—and all Snapchatters—across the globe, regardless of location.
Information for individual countries is available for download via the attached CSV file:

Download CSV

Region	Content & Account Reports	Content Enforced	Unique Accounts Enforced
North America	6,005,795	2,721,994	1,523,325
Europe	3,859,365	1,218,221	745,452
Rest of World	7,956,375	2,420,379	1,419,626
Total	17,821,535	6,360,594	3,629,674

Australia

Austria

Belgium

Brazil

Canada

Denmark

Finland

France

Germany

India

Iraq

Ireland

Italy

Mexico

Netherlands

New Zealand

Norway

Poland

Saudi Arabia

Spain

Sweden

Turkey

United Arab Emirates

United Kingdom

United States

Government & Intellectual Property Removal Requests

Learn More

About Transparency Reporting

Learn More

Glossary of Transparency Report

Learn More